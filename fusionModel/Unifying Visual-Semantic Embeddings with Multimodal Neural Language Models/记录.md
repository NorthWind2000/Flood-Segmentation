题目：Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models

# 一、Introduction

本文描述了一种新的方法来解决图像字幕生成问题，该方法被嵌入到编码器-解码器模型的框架中。对于编码器，我们学习一个联合的图像-句子嵌入，其中使用长短期记忆(LSTM)递归神经网络对句子进行编码。将深度卷积网络的图像特征投影到LSTM隐藏状态的嵌入空间。为了学习对图像及其描述进行排序，将成对排序损失最小化。在解码方面，我们引入了一种新的神经语言模型，称为结构-内容神经语言模型（SC-NLM）。SC-NLM与现有模型的不同之处在于，它根据编码器生成的分布式表示，将句子的结构与其内容分离开来。

## 1.1 生成图像描述

编码器为我们提供了一种对图像和字幕进行排序并开发良好评分函数的方法，而解码器可以使用所学的表示来优化评分函数，作为生成和评分新描述的方法。

## 1.2 机器翻译的编码器-解码器方法

神经网络机器翻译(NMT)的目标是开发具有大型神经网络的端到端翻译系统，而不是将神经网络用作现有基于短语的系统的附加特征函数。NMT方法基于编码器-解码器原理。也就是说，编码器用于将英语句子映射到分布式向量。然后，解码器根据该向量生成源文本的法语翻译。目前的方法包括使用卷积编码器和RNN解码器[8]，RNN编码器和RNN解码器[9,10]，以及LSTM编码器和LSTM解码器[11]。虽然仍然是一个新兴的研究领域，这些方法已经实现了性能与强大的基于短语的系统相媲美。

# 二、用于排序和生成的编解码器模型

## 2.1 Long short-term memory RNNs

长短期记忆是一种递归神经网络，它结合了一个内置的记忆单元来存储信息和利用长程上下文。

> $X_t$表示t时刻的训练实例的矩阵。在我们的例子中，$X_t$表示训练批次中每个句子的第t个单词的单词表示矩阵。
>
> $(I_t,F_t,C_t,O_t,M_t)$表示LSTM的时刻t的输入、遗忘、单元、输出、隐藏状态。

## 2.2 多模态分布表示

优化下面的ranking loss：
$$
min_\theta \sum_x\sum_kmax\{0,-\alpha-s(x,v)+s(x,v_k)\}+\sum_v\sum_k\{0,\alpha-s(v,x)+s(v,x_k)\}
$$

> $W_I\in R^{K\times D},W_T\in R^{K\times V}$分别表示图像嵌入矩阵和单词嵌入矩阵。
>
> 图像描述$S=\{w_1,…,w_N\},w_i\in R^K,i=1,…,n$，是单词的表示。
>
> v是LSTM在第N时刻的隐藏状态。
>
> $q\in R^D$是图像特征向量，令$x=W_i.q\in R^K$是图像嵌入。
>
> $s(x,v)=x.v$是评分函数。
>
> $\theta$表示所有可学习的参数。
>
> $v_k和x_k$表示不对应的单词嵌入和图像嵌入。

## 2.3 (Log-bilinear neural language models)对数双线性神经语言模型

