题目：Deep Multimodal Representation Learning:A Survey

# 一、Introduction

由于来自不同模态的特征向量最初位于不相等的子空间中，因此与相似语义相关联的向量表示将完全不同。 解决这个问题的一种流行方法是将异构特征投影到一个公共子空间中，在该子空间中，具有相似语义的多模态数据将由相似向量表示[5]。因此，**多模态表征学习的主要目标是缩小联合语义子空间中的分布差距**，同时保持特定于模态的语义完好无损。 

一般来说，基于多模态数据的机器学习任务包括三个必要步骤：模态特征提取、多模态表示学习（旨在将不同模态的不同特征集成到一个公共子空间中）和推理步骤（如分类或聚类）。

# 二、深度多模态表征学习框架

## 2.1 特定模态表征

尽管各种不同的多模态表征学习模型可能具有相似的体系结构，但用于提取特定模态特征的基本组件可能彼此有很大不同。

### 2.1.1 联合表示

除了在不同的隐藏层中进行融合过程（通常称为加法）之外，一些文献中还采用了乘法方法。在情感分析任务中，Zadeh等人[10]提出将语言、视频和音频模态融合到一个张量中，张量由所有特定模态特征向量的乘积构成。

**由于联合表示倾向于在忽略模态特定信息的同时保留模态间的共享语义，因此不能自动保证互补性。**（求同）

与其他框架相比，联合表示的优点之一是，由于无需明确协调模式，因此可以方便地融合多种模式。另一个优点是共享的公共子空间往往是模态不变的，这有助于将知识从一个模态转移到另一个模态。然而，该框架的缺点之一是，它不能用于推断每个模态的独立表示。 

### 2.1.2 协同表示

协同表示框架不是学习联合子空间中的表示，而是在某些约束条件下学习每个模态的分离但协调的表示。由于不同模态中包含的信息是不平等的，**学习分离表示有助于保持独有的、有用的模态特定特征**。 （求同存异）

根据约束条件分类，协同表示可以分为：基于跨模态相似性的和基于跨模态相关性的。

- 基于跨模态相似性的方法旨在学习一个公共子空间，在该子空间中，可以直接测量来自不同模态的向量距离[75]。
- 基于跨模态相关性的方法旨在学习一个共享子空间，从而使来自不同模态的表示集的相关性最大化[5]。 

**跨模态排序**

一个广泛使用的约束是跨模态排序。以视频-文本嵌入为例，定义视频和文本的匹配嵌入向量为$(v,t)\in D$，优化的目标为：
$$
rankLoss=\sum_v\sum_{t-}max(0,\alpha-S(v,t)+S(v,t-))+\sum_t\sum_{v-}max(0,\alpha-S(t,v)+S(t,v-))
$$

> $\alpha$ 代表间距，S是相似度计算函数，t-是与v不匹配的向量，v-是与t不匹配的向量。

基于跨模态排序约束，已经开发了多种跨模态应用程序。例如，Frome等人[34]使用点积相似性和边际秩损失的组合来学习视觉识别的视觉语义嵌入模型（DeViSE）。首先预先训练一对深层网络，将图像及其相关标签映射到嵌入向量v和t中，然后利用跨模态相似性模型学习两种模态的共享语义嵌入空间。每个训练样本的损失函数可定义如下： 
$$
loss(v,t)=\sum_{t-}max(0,\alpha-tMv+t^-Mv)
$$

> 其中M是用于将v转换为共享语义嵌入空间的线性变换矩阵，t和Mv之间的点积是用于训练和测试的相似性度量。
>
> 在（5）中的约束条件下，该模型期望匹配向量之间产生比不匹配向量之间更高的点积相似度，从而赋予嵌入图像丰富的语义信息，这些信息是从语言模态传递来的。

**欧几里德距离**

除了跨模态排序，另一个广泛使用的约束是欧几里德距离。这一类的主流方法是最小化成对样本的距离[33]、[77]、[78]。Pan等人[33]提出的模型就是一个例子，该模型旨在学习用于生成视频描述的视觉语义嵌入。该模型将视觉和语言表达都投射到一个低维嵌入空间中，在该空间中，成对样本之间的距离被最小化，这样视觉嵌入的语义将与其相关句子一致。该约束可以表示为损失项：
$$
distanceLoss=\sum_{(v,s)\in D}|||T_vv-T_sS|
$$

> $T_v$和$T_s$是视频v和句子s的变换矩阵。

另一个例子是Liong等人[78]提出的跨模态匹配模型，该模型旨在通过最小化所有层上隐藏表示的差异来减少成对数据的模态间隙。假设视觉模态v和文本模态t是通过齐次前馈神经网络编码的，损失可以表示为：
$$
distanceLoss=\sum_{l=1}^{L-1}\sum_{i=1}^N||h_{it}^l-h_{iv}^l||
$$

> 其中，l表示两个模态特定网络的一层，i表示训练数据的一对实例，h表示隐藏表示。

**保持模态内的相似性结构**

除了学习模态间的相似性度量，跨模态应用的另一个关键问题是保持模态内的相似性结构。一种广泛使用的策略是对学习到的特征进行分类，使其在每种形态中都具有区分性[30]，[79]。此外，另一种方法是在每个视图中保持邻域结构。 

与其他框架相比，协同表示倾向于在每种模态中保留独特且有用的特定模态特征[31]。由于不同的模态编码在分离的网络中，其优点之一是每个模态都可以单独推断。这种特性也有利于跨模式迁移学习，目的是在不同的模式或领域之间转移知识。这种框架的一个缺点是，在大多数情况下，很难学习两种以上模式的表示法。

