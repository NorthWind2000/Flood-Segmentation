BASNet: Boundary-Aware Salient Object Detection

# Introduction

​		人类视觉系统有一种有效的注意机制，可以从视觉场景中选择最重要的信息。计算机视觉旨在通过两个研究分支对这种机制进行建模：眼睛注视检测[20]和显著目标检测[3]。我们的工作集中在第二个分支上，旨在准确地分割输入图像中突出物体的像素。研究结果可直接应用于图像分割/编辑[53,25,11,54]和操作[24,43]，视觉跟踪[32,52,55]和用户界面优化[12]。

​		最近，全卷积神经网络（FCN）[63]已被用于显著目标检测。尽管与传统方法相比，这些方法取得了显著的结果，但其预测的显著性图在内部结构或边界仍然是有缺陷的。

​		在精确的显著性目标检测中有两个主要挑战：（i）显著性主要是在整个图像的全局对比度上定义的，而不是局部或像素级的特征。为了获得准确的结果，开发的显著性检测方法必须理解整个图像的全局意义以及对象的详细结构[6]。为了解决这个问题，需要聚合多层次深层特征的网络；（ii）大多数显著目标检测方法都使用交叉熵（CE）作为训练损失。**但是，使用CE损失训练的模型在区分边界像素时通常信心不足，导致边界模糊。** 其他损失，如联合交叉（IoU）损失[56,42,47]、F度量损失和骰子分数损失[8]是针对有偏训练集提出的，但它们不是专门为捕获精细结构而设计的。 **为了应对上述挑战，我们提出了一种新的边界感知网络，即BASNet，用于显著目标检测，该网络可以实现高质量边界的精确显著目标分割**。为了同时捕获全局（粗略）和局部（精细）上下文，提出了一种新的预测-细化网络。它将一个类似于UNet的[57]深度监督[31,67]编解码器网络与一个新的残差细化模块组装在一起。编码器-解码器网络将输入图像传输到概率图，而精化模块通过学习粗糙显著性图和地面真值之间的残差来精化预测图（见图2）。[50,22,6]在显著性预测或多尺度中间特征映射上迭代使用细化模块，与之相反，我们的模块在原始尺度上仅用于显著性预测一次。（ii）为了获得高置信度显著性图和清晰的边界，我们提出了一种混合损失，它结合了二进制交叉熵（BCE）[5]、结构相似性（SSIM）[66]和IoU损失[42]，期望分别从像素级、面片级和地图级的地面真实信息中学习。我们没有使用显式边界损失（NLDF+[41]，C2S[36]），而是隐式地将精确边界预测的目标注入混合损失中，考虑到它可能有助于减少交叉传播在边界和图像上其他区域上学习到的信息时产生的虚假误差。  

# BASNet

## Overview of Network Architecture

拟议的BASNet由两个模块组成，如图2所示。预测模块是一个类似UNet的密集监督编码器-解码器网络[57]，它学习从输入图像预测显著性图。多尺度残差细化模块（RRM）通过学习显著性图和地面真值之间的残差来细化预测模块的显著性图。 

## Predict Module

受U-Net[57]和SegNet[2]的启发，我们将显著对象预测模块设计为一个编码-解码网络，因为这种结构能够同时捕获高层全局上下文和底层细节。为了减少过度拟合，每个解码器级的最后一层由HED[67]启发的地面真相监督（见图2）。编码器部分有一个输入卷积层和六个由基本res块组成的级。输入卷积层和前四级采用ResNet-34[16]。不同的是，我们的输入层有64个卷积滤波器，大小为3×3，步幅为1，而不是7×7，步幅为2。此外，在输入层之后没有池操作。这意味着第二阶段之前的特征地图与输入图像具有相同的空间分辨率。这与最初的ResNet-34不同，它在第一个特征图中具有四分之一的分辨率。这种自适应使网络能够在早期层中获得更高分辨率的特征图，同时也降低了整体感受野。为了获得与ResNet-34相同的感受野[16]，我们在ResNet-34的第四阶段之后增加了两个阶段。这两个阶段都由三个基本res块组成，在大小为2的非重叠最大池层之后有512个过滤器。