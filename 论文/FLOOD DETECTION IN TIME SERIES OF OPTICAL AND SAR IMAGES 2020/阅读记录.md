题目：Flood detection in time series of optical and SAR images

# 一、Introduction

**之前的数据集：**
最近，提出了关于自然灾害检测的新数据集，他们大多是由RGB或者多光谱图像构成。这些数据集是由高分辨率的传感器采集而成。

> *卫星*
>
> 时间上：Landsat、Sentinel
>
> 空间上：Quickbird、WorldView

人工智能，尤其是深度学习技术，已经证明了这些数据集在检索语义地面覆盖信息和特定行为方面是有效的。

**之前数据集的不足：**

① 在观察云层覆盖区域时，光学图像上时间序列的分析是不可能的。

② 湿地和洪水很难通过视觉观察到。

**我们的方案：**

SAR图像可以在没有太阳光照的情况下获得，而且不受云层覆盖的影响。像`Sentinel-1`这样的卫星可以提供大量高时频的数据（六天一张图像）可以监测地球的大片区域。`因此，需要利用被动的光学成像和主动的雷达成像的新的机器学习方法`。

最近的研究表明，多模式机器学习可以利用多个传感器的互补信息提高模型的准确性。

**我们的数据集：**

本文介绍了由Sentinel-1和Sentinel-2图像组成的新SEN12-FLOOD数据集，以促进新洪水检测技术的发展。然后，我们为多模态时间序列分析提出了一种基于现成深度网络的第一基线，用于对数据集中的图像进行分类。

# 二、Presentation of the sen12-flood dataset

​		MediaEval 2019多媒体卫星任务提供的以城市为中心的卫星序列可访问一系列Sentinel-2图像。观测区域对应于非洲、伊朗和澳大利亚的城市及其周围地区。**Sentinel-2上的数据集：由12个波段、10m地面采样距离组成，并进行了2A级大气校正。**在这里，我们提出了一个新的数据集，对应Sentinel 1的相同区域和周期。由于Sentinel-1不受云层的影响，因此在相同的时间内SAR图像多于Sentinel-2图像。这个SAR数据集由大约两倍于光学数据集的图像组成。**为了利用SAR和光学模式，我们将MediaEval数据集和我们自己的数据集合并成新的SEN12-FLOOD数据集。**

​		每个图像都有一个二进制标签，指定洪水事件在观察区域中是否可见。标签由旧的MediaEval2019数据集提供。Sentinel-1的数据是在VV和VH模式下获得。SAR图像采用地面距离探测高分辨率(GRDH)产品，分辨率为10m x10m。**数据集由412个时间序列组成，每个序列中由4到20个光学图像和10到58个SAR图像。平均每个序列有9个光学图像和14个SAR图像。**洪水事件发生在40%的光学哨兵2号图像和47%的SAR哨兵1号图像中。**一旦序列中发生洪水，所有后续图像都被标记为洪水。**

# 三、Benefit of Multispectral and SAR dataset

​		该数据集用于训练用于双模（多种图像数据）和多时相洪水分类的新神经网络结构。

​		

# 四、Flood detection

