# CNN与FCN

- 通常cnn网络在卷积之后会接上若干个全连接层，将卷积层产生的特征图（feature map）映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像的分类的概率，如ALexNet网络最后输出一个1000维的向量表示输入图像属于每一类的概率。
- FCN对图像进行像素级的分类，从而解决了语义级别的图像分割问题。与经典的CNN在卷积层使用全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷基层的特征图（feature map）进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测，同时保留了原始输入图像中的空间信息，最后奇偶在上采样的特征图进行像素的分类。
  - 全卷积网络(FCN)是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。
- FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,7,7）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。 

> 简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，输出一张已经label好的图。

# 一、Introduction

​		在神经网络从粗糙到精确发展的下一步是对每一个像素进行预测。之前使用convnets做语义分割，该方法是将每个像素标记为与其相近的对象或区域的类别。

​		**我们提出的完全卷积网络（FCNs）在语义分割上的端到端、像素到像素的训练，超过了之前的最佳结果，而且不需要更多的机器。**现有网络的完全卷积版本可以预测任意尺寸输入的密集输出。每次对整个图像学习和推理是通过密集的前馈计算和反向传播实现的。网络中的上采样层利用网络中的子采样实现像素级别的预测和学习。

​		分块训练很常见，但是缺乏完全卷积的效率。我们的方法不需要前处理和后处理过程。我们的模型通过将分类领域的最新模型重新解释完全卷积和微调它们学到的表征的方式。将其转化为密集预测。

# 二、Related work

与现有的方法不同，我们采用并扩展了深度分类体系结构，使用图像分类作为有监督的预训练，并完全卷积地进行微调，以简单有效地从整个图像输入和整个图像ground thruth中学习。

# 三、Fully Convolutional Networks

​		convnet中的每一层输出是一个大小为h×w×d的三维数组，其中h和w包含空间维度，d是特征或通道维度。第一层是一个大小为hxw，d通道的图像。与图像中的位置通过路径连接的更高层中的位置，称为他们的接收场（receptive fields）。

​		
